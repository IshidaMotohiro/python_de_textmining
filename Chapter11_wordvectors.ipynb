{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 単語分散表現\n",
    "\n",
    "本章では、最初に異なるテキストどうしの類似度（近さ）をはかる方法について説明します。単純な BoW （文書単語行列）から紹介し、\n",
    "次に「意味を考慮して形態素をデータ化する方法」と、これを活用してテキストの類似度を調べる方法を説明します。\n",
    "\n",
    "\n",
    "## 文書ベクトル\n",
    "\n",
    "まずベクトルという概念を説明します。\n",
    "\n",
    "たとえば以下では A と Bという2つのリストを用意しています。それぞれの要素は整数ですが、これらがベクトルにあたります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 3]\n",
      "[3 7]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "A = np.array([7,3])\n",
    "B = np.array([3,7])\n",
    "print(A)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGiCAYAAADNzj2mAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA++ElEQVR4nO3dd3wUdeLG8c9usuk9ISSIECAgFlAELCACdgFFsCDCT1BEFCSgICoigooK5+EJeuopioo06SIiRVSKChbuRBQMxQKEJJBeN9n5/YGulwtIySYzu/u8X6/8sd/dnXnCN5CH2fnO2AzDMBARERGxELvZAURERET+lwqKiIiIWI4KioiIiFiOCoqIiIhYjgqKiIiIWI4KioiIiFiOCoqIiIhYjgqKiIiIWI4KioiIiFiOCoqIiIhYTuDJvmH79u0sW7aMPXv2kJOTw+jRo7ngggvczxuGwfz581m7di1FRUW0bNmSu+66i+TkZI8GFxEREd910kdQysrKSElJYdCgQUd9funSpXz44YcMHjyYp59+muDgYCZNmkR5eXmNw4qIiIh/OOmC0qZNG2699dYqR03+YBgGK1asoHfv3rRv357GjRtz3333kZOTw5YtWzwSWERERHyfR89ByczMJDc3l9atW7vHwsLCSE1NZefOnUd9j9PppLi4uMqX0+n0ZCwRERHxMid9Dspfyc3NBSA6OrrKeHR0tPu5/7V48WIWLFjgftyxY0dGjBjhyVgiIiLiZTxaUE5Fr1696NGjh/uxzWYDICcnh4qKCrNiye9sNhsJCQlkZ2djGIbZcfya5sI6NBfWobmwjsDAQGJjYz23PY9tCYiJiQEgLy+vSsi8vDxSUlKO+h6Hw4HD4ag2XlFRoY96LOCPwuh0OvWX32SaC+vQXFiH5sJ3efQclMTERGJiYvjuu+/cY8XFxaSnp9OiRQtP7kpERER82EkfQSktLSUjI8P9ODMzk7179xIREUFCQgLdunVj0aJFJCcnk5iYyNy5c4mNjaV9+/YeDS4iIiK+66QLyq5du5g4caL78dtvvw1A586dGTZsGD179qSsrIxXX32V4uJiWrZsydixYwkKCvJcahEREfFpNsOiH9plZWXpHBQLsNlsJCcnc+DAAX2+azLNhXVoLqxDc2EdDoeDevXqeWx7uhePiIiIWI4KioiIiFiOCoqIiIhYjgqKiIiIWI4KioiIiFiOCoqIiIhYjgqKiIiIWI4KioiIiFiOCoqIiIhYjgqKiIiIWI4KioiIiFiOCoqIiIhYjgqKiIiIWI4KioiIiFiOCoqIiIhYjgqKiIiIWI4KioiIiFiOCoqIiIhYjgqKiIiIWI4KioiIiFiOCoqIiIhYjgqKiIiIWI4KioiIiFiOCoqIiIhYjgqKiIiIWI4KioiIiFiOCoqIiIhYjgqKiIiIWI4KioiIiFiOCoqIiIhYjgqKiIiIWI4KioiIiFiOCoqIiIhYjgqKiIiIWI4KioiIiFiOCoqIiIhYjgqKiIiIWI4KioiIiFiOCoqIiIhYjgqKiIiIWI4KioiIiFiOCoqIiIhYjgqKiIiIWI4KioiIiFiOCoqIiIhYjgqKiIiIWI4KioiIiFiOCoqIiIhYjgqKiIiIWI4KioiIiFiOCoqIiIhYjgqKiIiIWI4KioiIiFiOCoqIiIhYjgqKiIiIWI4KioiIiFiOCoqIiIhYjgqKiIiIWI4KioiIiFiOCoqIiIhYjgqKiIiIWI4KioiIiFiOCoqIiIhYTqCnN+hyuZg/fz7r168nNzeXuLg4OnfuzI033ojNZvP07kRERMQHebygLFmyhNWrVzNs2DAaNmzI7t27+ec//0lYWBjdunXz9O5ERETEB3m8oOzcuZN27dpx/vnnA5CYmMiGDRtIT0/39K5ERETER3m8oLRo0YK1a9eyf/9+GjRowN69e9mxYwe33377UV/vdDpxOp3uxzabjdDQUGw2mz4SsoA/5kBzYT7NhXVoLqxDc2Ednp4Dm2EYhic36HK5mDNnDsuWLcNut+Nyubj11lvp1avXUV8/f/58FixY4H7cpEkTJk+e7MlIIiIi4mU8XlA2btzIrFmz6N+/P6effjp79+5l5syZ3H777XTp0qXa6491BCU7O7vKuJjDZrORlJRERkYGHv5RkZOkubAOzYV1aC6sw+FwkJCQ4LHtefwjnlmzZtGzZ086duwIQKNGjcjKymLJkiVHLSgOhwOHw1Ft3DAM/bBZiObDOjQX1qG5sA7Nhfk8/efv8euglJWVYbdX3azdbtcPjoiIiJwwjx9Badu2LYsWLSIhIYGGDRuyd+9eli9fTteuXT29KxEREfFRHi8od955J/PmzeP1118nLy+PuLg4rrzySm666SZP70pERER8lMcLSmhoKAMHDmTgwIGe3rSIiIj4Cd2LR0RERCxHBUVEREQsRwVFRERELEcFRURERCxHBUVEREQsRwVFRERELEcFRURERCxHBUVEREQsRwVF5H9UVJidQEREVFBE/sv33wfSpk19du0KMDuKiIhfU0ER+d3774fQr188AHFxLpPTiIj4N4/fi0fE2xgGTJkSwTvvhJOTE0CDBhXExBhmxxIR8WsqKOLXysvhnnti2bgxmMLCIwcUQ0LAZjM5mIiIn1NBEb91+LCdvn3j2LEjEKfzz087Q0J09ERExGwqKOKXduwIZMCAOH79tfpfgYSEShMSiYjIf9NJsuJ3Vq4M5tZb449aTgAaN1ZBERExm46giN8wDJg2LYLXXw/n8OFjLyNu3txZh6lERORoVFDELzidMHx4DJ98EkxBwbHLSUiIi5QUHUERETGbCor4vNxcG/36xbN9eyDl5X/9qWZYmEGDBiooIiJm0zko4tN27QqgW7d6bN3qOG45AXA4qJOCMmfOHPr27Vvr+7n33nt55ZVXan0/IiKepoIiPmvduiBuvjmBn38OBE7swiYBAQZRUae+zHjkyJGcdtpp7q+zzz6bfv36sX37dvdrSktL+dvf/sYDDzzgHluxYgXXXnstZ555JqmpqVx55ZUsWLDgpPb1x1fXrl3drxkxYgTTp08nPz//lL8nEREzqKCIT3r11XBGjIjl4MGTu6dOaKhR44u0de3alW+//ZZvv/2WefPmERAQwIABA9zPf/DBB0RERNC+fXv3WExMDGlpaSxbtow1a9bQp08fHnjgAT755JNj7ueJJ55w7+fbb79ly5YtxMTE0KNHD/drWrZsSePGjVm0aFHNvikRkTqmgiI+pbISRoyI4R//iOTQoZO/4Z8nLtIWFBREYmIiiYmJnHPOOdx3333s37+fQ4cOAbB06VKuvPLKKu/p0KED1157Lc2bNyclJYW77rqLM888k82bNx9zP1FRUe79JCYm8p///Ie8vDz69OlT5XVXXnklS5curfH3JSJSl1RQxGcUFNi48cZ4li8PIT//1H60ExI8e5PAoqIiFi5cSEpKCrGxsQBs2bKF1q1bH/M9hmGwfv16du3axUUXXXTC+5ozZw6dOnWiYcOGVcbPO+88tm7dSllZ2al9EyIiJtAqHvEJP/8cQL9+8ezdG4BhnPpnNJ5YYrxmzRqaN28OQHFxMfXr1+ett97CbreTl5dHfn4+SUlJ1d6Xn59P27ZtKS8vJyAggKeffppLL730hPaZkZHBunXrePHFF6s9V79+fcrLy8nKyqpWXkRErEoFRbzepk1BDB8eS0bGyX+k8788cZG2Dh068MwzzwCQl5fHW2+9Rf/+/fnggw9wOBwABAcHV3tfREQEq1atoqioiA0bNjBx4kQaNWpEhw4djrvP9957j6ioKK655ppqz4WEhABQUlJSk29LRKROqaCIV8vIsNO/fzxlZTW//bCnLtIWFhZGkyZN3I9btWpFy5Yteffdd7n//vux2Wzk5eVVe5/dbne/75xzziE9PZ0XX3zxuAXFMAzmzp3LjTfeSFBQULXnc3NzAYiPj6/BdyUiUrd0Dop4taQkFx99lMU99xSSmuqkXr1KbLZTO9E1PLx2LtJms9mw2+2UlpYSFBREixYt2Llz53Hf53K5KC8vP+7rPv/8c/bu3XvM66rs2LGD5ORk4uLiTjq7iIhZdARFvF7z5hU89lg+jz0Gv/4awMKFoSxfHsrhw3ays+1UVp7Y0ZXAQEhOrnlBKS8vJzMzEzjyEc+bb75JUVGRe+VO586d2bx5M4MHD3a/Z/r06Zx77rk0btyY8vJy1q5dy8KFC90fFf2VOXPm0KZNG1q2bHnU57/88ks6d+5c4+9LRKQuqaCITzn99EpGjixk5MhCsrLsLF0awlNPRWMYYLMZOJ3HPmgYGFizi7T9Yd26dbRp0wY4cl5Jamoqr776qvujmr59+3LttdeSn59PVFQUcORk2kceeYSMjAxCQkJo1qwZ06ZNo2fPnu7tPvfccyxcuJDPP//cPZafn8+KFSt44oknjpqltLSUjz76iFmzZtX4+xIRqUs2wzBq/i9yLcjKysLp1F1lzWaz2UhOTubAgQNY9EflL1VUQOPGDVi+PIudOwOZOzeMX38NICfHTmlp1bLSrJmTzz7LqpNcd999N61atWL48OEn/J6RI0cSFhbGM888c8Jz8dZbb7Fy5UrmzJlzqlHlKLz974Uv0VxYh8PhoF69eh7bno6giE+75ZZ4GjeuoE0bJ23aOOnTp4SSEhtr1wbz7rth7NoVSF6encJCu0cu0naiHnvsMVavXn3CrzcMg02bNlU5enIiHA4HTz755MnGExExnY6gyF/y5v+dZGTYads2ifT0A4SGHj270wkbNwbzzjthnHmmk9GjC+s45Ynz5rnwNZoL69BcWIeOoIicoLZtk7jjjsJjlhM4cvfiLl3K6NJFV1kVEbESLTMWn7R+/ZHrgTz5pO7iKyLijVRQxCfdemsCb755qMZ3JhYREXOooIjPmTw5EoCrrtLHNiIi3koFRXxKeTlMmxbJF18cNDuKiIjUgAqK+JTrrkvgrLOcnH665y9ZLyIidUereMRn/PprANu2BbF7936zo4iISA3pCIr4jIsuqk9aWgHBwWYnERGRmlJBEZ+watWRVvLQQwUmJxEREU9QQRGvZxhwxx3xzJ59yOwoIiLiISoo4vUmTDhyR+DOnbWsWETEV6igiFcrKYHXX4/g668zzI4iIiIepIIiXu2KKxK54IIykpJcZkcREREP0jJj8Vq7dgWwd28gn36aaXYUERHxMB1BEa916aX1eeSRfAJVs0VEfI4KinilpUtDALjvvkKTk4iISG1QQRGvYxgwdGgcixdnmx1FRERqiQqKeJ3Ro6MBuOCCcpOTiIhIbVFBEa9SWGhj7txw/vMfLSsWEfFlKijiVTp2TOSyy0qJj9eyYhERX6aCIl7jhx8Cyc4OYObMw2ZHERGRWqaCIl7jiisSefLJXAICzE4iIiK1TQVFvMKcOaEA3HlnsclJRESkLqigiOW5XDB6dCwffphldhQREakjKihieffeG0t4uIvWrZ1mRxERkTqii4SLpeXm2li+PJTt2w+YHUVEROqQjqCIpbVvX5/rrismOtowO4qIiNQhFRSxrH//20FxsZ2XX841O4qIiNQxFRSxrG7d6jF1ag42m9lJRESkrqmgiCXNmBEGQJ8+JSYnERERM9TKSbKHDx9m1qxZbN26lbKyMpKSkhg6dCjNmjWrjd2Jj6mshPHjY1i7NtPsKCIiYhKPF5TCwkIee+wxzj77bMaOHUtUVBQHDhwgPDzc07sSHzVgQByJiZW0bFlhdhQRETGJxwvK0qVLiY+PZ+jQoe6xxMRET+9GfFR2tp1160LYuVPLikVE/JnHC8pXX33Fueeey9SpU9m+fTtxcXFcddVVXHHFFUd9vdPpxOn88wJcNpuN0NBQbDYbNp0dabo/5qCu5uLcc5Po27eYiAgAzf9/q+u5kGPTXFiH5sI6PD0HNsMwPHqBiX79+gHQvXt3Lr74Ynbt2sWbb77J4MGD6dKlS7XXz58/nwULFrgfN2nShMmTJ3sykniJ9evh0kuPXNpe/9aIiPg3jx9BcblcNGvWjNtuuw04Ujh++eUXVq9efdSC0qtXL3r06OF+/EcDy87OrnJkRcxhs9lISkoiIyMDD3fZai69NJlXXskhI6O0VvfjrepyLuSvaS6sQ3NhHQ6Hg4SEBI9tz+MFJTY2loYNG1YZa9iwIV9++eVRX+9wOHA4HNXGDcPQD5uF1PZ8TJsWAcB115Wgaf9r+rthHZoL69BcmM/Tf/4evw7KGWecwf79+6uM7d+/n3r16nl6V+IjnE6YPDmK9esPmh1FREQswuMFpXv37vz0008sWrSIjIwMNmzYwNq1a7n66qs9vSvxETffHE+TJhU0bVppdhQREbEIj3/Ek5qayujRo5k9ezYLFy4kMTGRAQMG0KlTJ0/vSnzAgQN2tmwJJj19//FfLCIifqNWriTbtm1b2rZtWxubFh/Trl0SgwcXEhpqdhIREbES3YtHTPPJJ8EAPP54vslJRETEalRQxDT9+sUzc+YhXfNERESqUUERUzz7bCQAV15ZZnISERGxIhUUqXNlZTB9eiRffqllxSIicnQqKFLnunevR6tW5TRsqGXFIiJydLWyikfkWH75JYAffnCwZ4+WFYuIyLHpCIrUqYsvrs/IkQUEBZmdRERErEwFRerMypUhADz4YIHJSURExOpUUKROGAYMGhTHvHnZZkcREREvoIIidWLcuCgALrmk3OQkIiLiDVRQpNaVlNiYOTOCb77JMDuKiIh4CRUUqXWXXVaPiy8uo359l9lRRETES2iZsdSq9PRAfvklkPXrM82OIiIiXkRHUKRWde6cyKOP5hGoKiwiIidBBUVqzaJFoQAMHVpkchIREfE2KihSKwwDhg+PZcmSLLOjiIiIF1JBkVpx//0x2O0G7ds7zY4iIiJeSGcGiMcVFNh4770wvvtOy4pFROTU6AiKeFyHDolccUUJcXFaViwiIqdGBUU8avv2QA4fDuDNN3PMjiIiIl5MBUU86sorE3n66Vzs+skSEZEa0K8R8Zh33w0DYMCAYpOTiIiIt1NBEY9wuWDMmBhWrtSyYhERqTkVFPGIIUNiiYhw0aqVlhWLiEjNaZmx1FhOjo0VK0LZvv2A2VFERMRH6AiK1Nj55yfRq1cx0dGG2VFERMRHqKBIjXz7rYPychvTp+eaHUVERHyICorUSI8e9Xj++RxsNrOTiIiIL1FBkVP22mvhANxyS4nJSURExNeooMgpqayECROiWbcu0+woIiLig1RQ5JT07x9HUlIlLVpUmB1FRER8kJYZy0nLyrLz2Wch7NypZcUiIlI7dARFTtp55yXRv38R4eFaViwiIrVDBUVOyhdfBAHw7LN5JicRERFfpoIiJ+XGGxN49dXDWlYsIiK1SgVFTtg//hEBQI8epSYnERERX6eCIifE6YS//S2KDRsOmh1FRET8gAqKnJDeveNp3txJkyaVZkcRERE/oGXGcly//QZffx3Erl37zY4iIiJ+QkdQ5LhOPx2GDCkkJMTsJCIi4i9UUOQvrVt3ZFnx+PEFJicRERF/ooIif6lfv3g++AAtKxYRkTqlgiLHNGlSJADdupkcRERE/I4KihxVaSn885+RbN6sZcUiIlL3VFDkqLp1q8e555bTsKHL7CgiIuKHtMxYqvn55wB27HCwZ89+QCefiIhI3dMRFKmmQ4f6PPBAPkFBZicRERF/pYIiVaxYceRiJ6NGFZqcRERE/JkKirgZBgweHMe8edlmRxERET+ngiJujz4aBcAll5SbnERERPydCooAUFxs4623Ivj22wyzo4iIiKigyBFdutSjY8cyEhO1rFhERMynZcbCTz8Fsm9fIJs2ZZodRUREBNARFAG6dElk/Pg8AlVXRUTEIlRQ/NzChaEADBlSZHISERGRP6mg+DHDgLS0WJYtyzI7ioiISBUqKH5sxIgYAgMN2rZ1mh1FRESkCp114Kfy820sXBjGd98dMDuKiIhINTqC4qcuvrg+11xTQlycYXYUERGRalRQ/NC2bYHk5tp57bUcs6OIiIgclQqKH7r66kSefTYXu2ZfREQsSr+i/MysWWEA/N//FZucRERE5NhUUPyIywUPPRTDRx/pirEiImJttV5QlixZwi233MLMmTNre1dyHIMHxxIT4+KccyrMjiIiIvKXanWZcXp6OqtXr6Zx48a1uRs5AYcP21i5MpQfftCyYhERsb5aKyilpaVMnz6dIUOGsGjRomO+zul04nT+eaEwm81GaGgoNpsNm81WW/H8zvnnJ3HjjcVERwOc+J/rH3OguTCf5sI6NBfWobmwDk/PQa0VlNdff502bdrQunXrvywoixcvZsGCBe7HTZo0YfLkySQkJNRWNL/zxRfgdMJ774Vhs4Wd0jaSkpI8nEpOlebCOjQX1qG58D21UlA2btzInj17eOaZZ4772l69etGjRw/34z8aWHZ2dpUjK3LqLr44mWnTcsjIKD3p99psNpKSksjIyMAwdFE3M2kurENzYR2aC+twOBwePbjg8YKSnZ3NzJkzGTduHEFBQcd9vcPhwOFwVBs3DEM/bB7w6qvhANx4Ywk1+ePUfFiH5sI6NBfWobkwn6f//D1eUHbv3k1eXh4PPfSQe8zlcvHDDz+wcuVKZs+ejV1XCKsTlZXwxBPRfPKJlhWLiIh38XhBadWqFc8991yVsZdffpkGDRrQs2dPlZM61LdvPKedVkHz5lpWLCIi3sXjBSU0NJRGjRpVGQsODiYyMrLauNSezEw7GzcG89NPWlYsIiLeR4czfFSbNkkMGFBIWJg+kxUREe9Tqxdq+8OECRPqYjfyu02bjpycPGlSvslJRERETo2OoPigm29O4LXXDqPrFomIiLdSQfExf/97BADdup38NU9ERESsQgXFhzidMHVqFJs2HTQ7ioiISI2ooPiQG25IoEULJ40bV5odRUREpEbq5CRZqX379tnZujWIXbv2mx1FRESkxnQExUdccEESw4YVEBJidhIREZGaU0HxAWvXBgMwdmyByUlEREQ8QwXFyxkG3H57PLNmHTI7ioiIiMeooHi5p56KBKBr1zKTk4iIiHiOCooXKy2FV16JZMuWDLOjiIiIeJQKihe75pp6tG1bToMGLrOjiIiIeJSWGXupPXsC+OknB3v3almxiIj4Hh1B8VKXXFKf0aPzcTjMTiIiIuJ5KiheaPnyIxc7uf/+QpOTiIiI1A4VFC9jGDBkSBwLF2abHUVERKTWqKB4mYcfjgbgoovKTU4iIiJSe1RQvEhRkY1Zs8LZulXLikVExLepoHiRSy9N5NJLS6lXT8uKRUTEt2mZsZfYuTOQjIwANm8+aHYUEfEytuJicDoxoqLAZjM7jsgJUUHxEl27JjJhQh4BAWYnERFvE/HSS4TPmIErMhKCgzGCg3FFRVHZoAEVjRtT2bQplQ0aUFm/Pq6kJIzwcFNyTpkyhezsbKZMmVKr++nRowf33nsv3bt3r9X9SM2ooHiB994LBWDw4CKTk4iINyq8+25C580jcP/RL+xo2GwY4eEYISEQEIARGIgRHAzBwbhiY6k47TQqU1KoaNIEV3IylfXrU5mYCKGhJ5Xjq6++olevXnTp0oV33nmnynOZmZnMmDGDtWvXuscuvPBCfvvtt2rbGTBgAE8//fRR97FixQqmT5/O3r17cTqdNGnShCFDhnDTTTe5XzNixAgmTJjAtddei92uMx2sSgXF4gwDRo6MZfnyLLOjiIiXMqKjKbz7bqKmTMFeUlLteZthYCsshMKjX1sp+I/t2O24wsPhv4tMSMiRIzLx8VQ2bEhFkyZUpqRQ3qYNruTkKtuZO3cud9xxB3PnziUjI4OkpCT3c7Nnz6Zdu3Y0bNjQPbZixQoqKyvdj3/88Uf69u1Ljx49jvm9xsTEkJaWRmpqKg6HgzVr1vDAAw+QkJBAly5dALjssst48MEH+fjjj7niiiuO98cnJlFBsbjhw2MIDjZo08ZpdhQR8WLFgwYRPmsW9l27TnkbNpeLgIICKCj4y9cZwcHkjR9P8cCB7rGioiKWLVvGihUryMrKYv78+aSlpbmfX7ZsGbfffnuV7cTHx1d5/OKLL5KSksLFF198zH136NChyuO77rqL9957j82bN7sLSkBAAJdddhlLly5VQbEwHduysPx8G4sXh/H111pWLCI1FBBA3qRJVMbE1OpuKiMjKRo4sEo5AXj//fdJTU0lNTWV3r17M2/ePAzDACAnJ4edO3fSunXrY263vLycRYsW0adPH2wneKKvYRisX7+eXbt2cdFFF1V57rzzzmPz5s0n981JnVJBsbALLqjPtdeWEBtrmB1FRHxAeadOVJx5Zq1t3xUZSUnv3uSPH1/tuTlz5tC7d28AunbtSn5+Pp9//jkA+/btwzAM6tevf8xtr1y5kvz8fG655Zbj5sjPz6d58+akpKQwYMAAnnrqKS699NIqr0lKSmL//v24XLpsg1WpoFjUtm2BFBTY+de/csyOIiI+JHfq1CMnuHqYKzycku7dyZ80qdpz6enpbN26lRtuuAGAwMBArr/+eubMmQNAaWkpACEhIcfc/ty5c+natWuV81aOJSIiglWrVvHBBx8wZswYJk6cyKZNm6q8JiQkBJfLRVlZ2Yl+i1LHdA6KRV19dSJTpuSiE8xFxJMqGzWi9KqrCJszB9t/nYBaE66wMEqvuoq855476nVW5s6dS0VFBeeff757zDAMgoKCmDRpEnFxcQDk5uZWO+8E4LfffmP9+vW8/vrrJ5THbrfTpEkTAM455xzS09N58cUXq5yfkpOTQ1hYGKEnuRJJ6o5+/VnQW2+FAdCvX7HJSUTEF+U/9hiVf/FxyslwhYZS1qULudOmHbWcVFRUsGDBAsaPH8+qVavcX6tXryYpKYklS5aQkpJCZGQkP/3001H3MW/ePBISErj88stPLaPLRXl51fuX7dixg3POOeeUtid1QwXFYlwuGDs2htWrM82OIiI+yoiIoHD4cFxhYTXajis4mLKOHcl59VWOdbh3zZo15OXl0bdvX1q2bFnlq1u3bsydOxe73U6nTp2OetKqy+Vi3rx53HzzzQQGHv+g//Tp0/nss8/4+eef+emnn3jllVdYuHCh+/yXP2zevLnaeSliLSooFnPnnbHExlZy1lkVZkcRER9kP3yYmLQ0Yh55BHvxqR+ldQUFUX7hheTMmHHMcgJHTo695JJLiIqKqvZct27d+Pe//8327dvp27cvS5curXbS6vr169m3bx99+vQ56vZHjhzpXj4MUFxczCOPPMJll13GDTfcwIoVK5g2bRq33Xab+zUHDhzgq6++OuY2xRpsxh/rvCwmKysLp9O/rv1x+LCdVq2S+PHHA0RGWmNabDYbycnJHDhwAIv+qPgNzYV1eNtcBPz6K9EPPUTIp58C4GzenNx//APKyogbNIiAnJM7Gd9wOChv145Dc+aAw+GRjIZh0KNHDwYPHuw+mfZE3HjjjVx99dUMGTLkhOdi0qRJ5OXl1fol9f2Nw+GgXr16HtueTpK1kHPPrc8ttxRZppyIiPcK/P57Yh54gKBt2wAou+giDq5fT2XTplVe52zVioDPPjvh7RqBgZSfdx6H3n3XY+UEjpS+yZMn8+OPP57we/Lz8/n5558ZPXo0Bce5eNx/i4+P5+677z6VmFKHdATFIrZscXDDDfX47bf9lrrZqLf9T9GXaS6sw6pzEfT558SkpbnvuVPSvTt5Tz2F6y+WFdv37aNejx4EZB7/vDfDbsfZujXZCxceudy9BVh1LvyRjqD4qBtuqMf06TmWKiciYnGGQcgHHxCblobt9+t5FA0YQNYjj2BERp7QJlynnUbJ9dcTPnMmtopjn/tm2O04zz6bQwsWWKaciG9TQbGAf/7zyK3Ne/eufhMvEZEqXC7C3nmHmLFj3UP5o0ZROGwYBAf/xRuPreDhhwlZuZLAo9w5GMAAKlq25NCCBRi6bojUERUUk1VUwKRJ0Xz66UGzo4iIVZWVEfHii0RNneoeyn36aYr794eAgBpv3ggNpeCBB4gePx77Ue5oXHHGGWQvXIgREVHjfYmcKBUUk916azyNGlWQmuqZKzqKiG+wFRQQ9cwzhL/1FnDkDsGHX32V0u7dj3pBtJoqueUWIl57DfsPP1QZd6amHiknR1kmLFKbVFBMdPCgnc8/DyY9/YDZUUTEAuyZmUSPG0foBx8AUJGcTPb8+ZR37Fj7O7fZyP3b34gbMICAQ4eO7L9JEw4tWoQRG1v7+xf5HyooJjr//CQGDiwkNFRnnov4q4Ddu4l58EGCv/gCgPJzziFz1Soqzj67zrM427ShvE0bQtesoaJxY7IXLsR1lHvjiNQFFRSTbNgQBMBTT+WbnERE6ppj61ZiRo7E8fu9Z0q7dOHgF19QefrpJieDvClTCLj9dg6/8QYuD92vR+RUqKCYpE+fBGbMOKxlxSJ+IviTT4gZPpyAw4cBKL7xRg4tWoTr9zv5WoWrfn2yP/rI7BgiKihmeO65I2fCX3NNqclJRKTWGAahixYRm5bmHiocMoSC0aMxaniTPhF/oIJSx8rL4fnno/j8cy0rFvE5FRWEv/EG0RMnuofyx46l8O67PXpZeBF/oIJSx66/PoGzznLSqJGWFYv4hJISIp9/nsiXXnIP5fz975Tccstf3uVXRP6aCkod+u23AL77Lojdu/ebHUVEasCWkwNjx5I8cyYArqgoDs2cSdkVV9TKNUpE/JEKSh268ML63HdfwalejVpETGTfv5/oRx4hdM2aIwPNm5O9bBnlbduaG0zER6mg1JE1a460kkceOfFbgouIuQJ37CBm1CiCvv0WgLJ27cj85BMqW7QgOTkZ54EDoDvoitQKFZQ6YBgwYEA8s2cfMjuKiBxH0ObNxIwYQeAvvwBQcvXVZHz1Fa7kZPdr9CGOSO1TQakDEyceuYdF585lJicRkWoMg5BVq4gZPhx7UREARbfdRta4cRjR0SaHE/FfKii1rKQEXnstgq++yjA7ioj8weUibM4cYsaMcQ8VpKVRMGIEhISYGExE/qCCUsuuuqoe7dqVkZzsMjuKiH9zOol4+WWiJk92D+VNnEjRHXdAQICJwUTkaFRQatHu3QHs3u3g44+1rFjEDLaiIiInTyZixgwAjIAAcl56iZKePbUcWMTiVFBqUadO9Xn44XxdQFKkDtmzs4kaP56wpUsBqExMJHvOHMovvdTkZCJyMlRQasn77x/5HHv48EKTk4j4voCffyZ6zBhCNmwAwNmyJVkffoizdWuTk4nIqVJBqQWGAffcE8eiRdlmRxHxWYHbthF7//04tm8HoKxjRw5u3EhlSoq5wUTEI1RQasGDDx5ZmnjhheUmJxHxLUHr1xM7YgQBB4/cbLP4+us5NHs2rnr1TE4mIp6mguJhRUU25swJ5z//0bJikRozDEKWLSM2LQ1bRQUAhXfcQcHDD2NERJgcTkRqkwqKh3XqlEjXrqXEx2tZscgpqawkfOZMosePdw/lP/gghUOHQlCQicFEpC6poHjQjz8GcvBgAFu2HDQ7ioh3KS0lcto0Il94wT2U++yzFPfrB3a7icFExCwqKB50+eWJPPFErq75JHICbPn5RE2aRPisWQC4wsM5PGMGpVdfrWuUiIgKiqfMnRsKwKBBxSYnEbEue0YG0Y8+SujKlQBUnH462YsWUX7hhSYnExGrUUHxAMOAUaNiWbEiy+woIpYTkJ5OzKhRBH/1FQDl555L5tq1VLRsaXIyEbEyFRQPGDo0htBQF+ee6zQ7ioglOL75hpiRI3Hs2gVA6eWXc3DzZipPO83kZCLiLTxeUBYvXszmzZvZt28fQUFBtGjRgv79+9OgQQNP78oS8vJsLFsWxvffHzA7ioh5DIPgjz8mNi0Ne24uAMU330z2kiUYcXHmZhMRr+TxgrJ9+3auvvpqmjVrRmVlJXPmzOGpp55i6tSphPjgbczbt69Pjx4lxMQYZkcRqVuGQeh77xF7//3uoYJ776Vw1CiM0FATg4mIL/B4QXn00UerPB42bBh33XUXu3fv5qyzzqr2eqfTidP550cjNpuN0NBQbDYbNoufyf+f/wRSVGTn1VdzLZ/1VP3xffnq9+dNLDEXFRWE/+tfRD31lHso/7HHKBo8GAL//OfE139aLDEXAmgurMTTc1Dr56AUFx9Z1RJxjKs+Ll68mAULFrgfN2nShMmTJ5OQkFDb0WqsQQN4/XVo0CDZ7Ci1LikpyewI8rs6n4uiIhg/HqZO/XPs7behf3+w2YgCouo2kWXo74V1aC58j80wjFr7bMLlcjFlyhSKiop48sknj/qaYx1Byc7OrjJuNW+8Eca4cdHs3+/b557YbDaSkpLIyMigFn9U5ATU5VzYDh8mauJEwt57D4DKuDjypk2j7LLLanW/3kJ/L6xDc2EdDofDowcXavUIyowZM/j111954oknjvkah8OBw+GoNm4YhmV/2CorYdy4aNasybRsRk+z8nz4m9qai4DffiP64YcJWbcOAGdqKlnLl+Ns0+a/d+7x/Xoz/b2wDs2F+Tz9519rBWXGjBl88803TJw4kfj4+NrajSkGDoyjXr1KzjyzwuwoIjUS+MMPxNx/P0HffQdA2YUXcvCzz6hs1szkZCLi7zxeUAzD4I033mDz5s1MmDCBxMRET+/CVIcO2fn44xB27PDtj3bEdwV9/jkxI0YQuG8fACXdupHx1lu46tc3OZmIyJ88XlBmzJjBhg0bGDNmDKGhoeT+fk2EsLAwgnzgTqStWydx661FREToUKJ4CcMg5MMPiUlLw15SAkDR//0fWWPHYkT56+mtImJ1Hi8oq1atAmDChAlVxocOHUqXLl08vbs6tWXLkYL13HN5JicROQ6Xi7B33yXm4YfdQwX330/B8OEQHGxiMBGRE+PxgjJ//nxPb9IybrghgZdfPqwbrYo1lZcT8eKLRP397+6h3EmTKP6//0O32BYRb6N78ZygF188ch2X668vNTmJyJ9sBQVEPvssETNnAmA4HBx++WVKr7sONWkR8WYqKCegogKeeSaKzz47aHYUEexZWUQ9+iihy5cDUJmURPa8eZRfconJyUREPEcF5QTcfHM8KSkVNGtWaXYU8VMBe/YQM2YMbNpEfaD87LPJ/OgjKs45x+xoIiK1QgXlODIy7GzeHEx6+n6zo4ifcfz738SMHIlj504ASi+9FHbv5kBIiC5IJSI+TwXlONq2TWLQoEJ0c1apC8GffkrM8OEEHDoEQHHv3hxasABXfDw2m43k5GQ4oGvwiIjvU0H5C599dmRZ8cSJ+SYnEZ9lGIQuXkxMWhq234+KFA4eTMGDD2KEh5scTkTEPCoof6Fv3wTefPOQFkOIZ1VUEP7mm0T/17WC8h9+mMJ77oGj3JdKRMQfqaAcw7PPRgJw1VVlJicRn1BSQuQ//kHkiy+6h3Kee46SPn3AbjcxmIiINamgHEVZGUyfHsmXX2pZsZw6W24uUU8+SfjcuQC4IiM59OablF15pa5RIiJyHCooR3HddQmcfXY5DRtqWbGcHPv+/UQ/8giha9YAUNG4MdlLllDevr3JyUREvIsKyv/49dcAvv8+iD17tKxYTkzgzp3EjBpF0DffAFDeti2Z69ZR0aKFyclERLyXCsr/uOii+owYUYAP3HhZapFjyxZiR4wg8OefASi58koytmzB1aCByclERHyDCsp/WbXqyF1ex4wpMDmJWI5hELx6NbHDh2MvLASgqG9fslaswIiJMTebiIgPUkH5nWHAHXfEM3duttlRxCpcLsLmziXmwQfdQwX33UfByJHoyn0iIrVLBeV3jz8eBUCnTuUmJxFTOZ1EvPIKUc8+6x7KmzCBojvugED9dRERqSv6FxcoKbExY0YEX3+dYXYUMYGtuJjIKVOIeO01AAybjZzp0ynp1UvLgUVETKKCAlx+eT0uuqiMpCSX2VGkjtgPHSLq8ccJW7wYgMqEBA7Nnk1Z584mJxMREVBBYdeuAH7+OZDPPss0O4rUsoBffiF6zBhC1q8HwHnGGWR9+CHO1q1NTiYiIv/L7wvKpZfWZ+zYPJ1e4KMCt20j5oEHCPr+ewDKOnTg4IYNVDZpYnIyERH5K379a3nJkhAAhg0rMjmJeFLQhg3EpqURcPDIrQpKrruOjFmzcCUmmpxMREROlN8WFMOAYcPiWLIky+woUlOGQcj77xOblobN6QSgcOBACh5+GCMy0uRwIiJyKvy2oIwaFQ1A+/ZOk5PIKamsJOztt4kZN849lD96NIXDhqHLAIuIeD+/LCiFhTbmzQvnP//RsmKvUlZG5LRpRP7jH+6h3GefpbhfP7DbzcslIiIe55cFpWPHRC6/vJT4eC0rtjpbfj5RTz9N+DvvAOAKDeXwa69Reu21ukaJiIgP87uCsn17INnZAcycedDsKHIM9oMHiR43jtAVKwCoOO00shcsoPzii01OJiIidcXvCsqVVyYyaVKuPhGwmIBdu4gZPZrgzZsBKG/dmsw1a6g480yTk4mIiBn8qqDMnn3kBm8DBxabnEQAHN9+S8yIETh27QKg9LLLOPjll1Q2bGhyMhERMZvfFBSXCx58MJYPP9SyYjMFf/wxMWlpBOTkAFB8881kL1mCERdncjIREbESvyko99wTS3i4i9attay4ThkGoQsXEjtihHuocMgQCkaPxggLMzGYiIhYmV8UlNxcGx98EMr27QfMjuIfKioIf/11op980j2UN24cRYMHo3sKiIjIifCL3xbt2tWnZ89ioqMNs6P4LFtJCRF//zuRL7/sHst5/nlKbr5Zy4FFROSk+XxB2brVQUmJnZdeyjU7is+xHT5M9BNPEPbeewC4YmI49NZblF1+uUqJiIjUiM8XlO7d6zF1ao5+X3pIwL59RD/8MCEffwyAs2lTspYtw9m2rcnJRETEl/h0QXn99XAA+vQpMTmJl9u2jfj+/Qn6978BKGvfnsxPP6UiNdXkYCIi4qt8tqBUVsLjj0fz8ceZZkfxSkFffklMWhqBv/0GQOW115Lxxhu4kpJMTiYiIv7AZ6+nOmBAHPXrV3LGGRVmR/EOhkHIhx+S1Lw5DU47jYTevSnr0oWMH34AwyB3xgyVExERqTM+eQQlO9vOunUh7NypZcV/yeUi7N13iXn4YfdQwYgRFKSlQUgIADadvCMiIibwyYJy7rlJ3HZbEeHhWlZcTXk5ES+9RNRzz7mHcp98kuIBAyAgwMRgIiIif/K5gvLll0EATJmSZ3IS67AVFhL57LNEvPkmAIbDweF//pPS66/XcmAREbEknysovXsn8Morh/3+9649K4uo8eMJW7YMgMr69cmeO5fyTp1MTiYiInJ8PlVQXnghAoDrris1OYk5AvbuJWbMGII3bgTAedZZZH70ERXnnGNyMhERkZPjMwXF6YQpU6LYsOGg2VHqlOO774gZMQLHjh0AlF5yCQc3baKycWOTk4mIiJw6nykoN90UT7NmTpo0qTQ7Sq0L+uwzYtPSCMjKAqD4hhs4NH8+roQEk5OJiIh4hk8UlAMH7Hz1VTDp6fvNjlI7DIPQpUuJGT4cm8sFQOGgQRQ89BBGeLjJ4URERDzPJwpKu3ZJ3H13IaGhZifxoMpKwt94g+gJE9xD+WPGUHjvvRAUZF4uERGROuD1BeWTT4IBGD8+3+QkHlBSQuQLLxA5fbp7KHfKFIr79gW7z170V0REpBqvLyj9+sXz1luHvHZZsS0vj6gnnyR8zhwAXOHhHH7jDUqvukrXKBEREb/l1QXl6acjAbjiijKTk5wc+4EDRI8dS+iqVQBUNGpE9uLFlF9wgcnJRERErMFrC0pZGbz0UiSbN3vHsuLAn34iZtQogr7+GoDyNm3I/PhjKs44w+RkIiIi1uO1BaVbt3q0bl3OaadZd1mx46uviB0xgsC9ewEoveIKMjZvxnXaaeYGExERsTivLCi//BLAjz862LPHYsuKDYPgNWuITUvDnn/kpN2iPn3IWr4cIzbW5HAiIiLewysLysUX1+eBB/KtsdrW5SJ0/nxiR41yDxUMG0bB/ffjW+ueRURE6o7XFZSVK0MAGDWq0LwQTicRr75K1DPPuIfyHn+cojvvhECv+yMVERGxHK/6bWoYMGhQHPPmZdf5vm3FxUT+7W9E/Otf7rGcadMo6d1by4FFREQ8zKsKyrhxUQBcckl5nezPfvgwUY8/TtiiRQBUxsVxaNYsyrp2rZP9i4iI+CuvKSglJTZmzozg228zanU/Ab/+SvRDDxHy6acAOJs3J+uDD3Ced16t7ldERET+5DUF5bLL6nHxxWUkJro8vu3A778n5oEHCNq2DYCyiy7i4Pr1VDZt6vF9iYiIyPF5RUFJTw/kl18CWb8+02PbDNq0iZi0NAIPHACgpHt3Mt55B1diosf2ISIiIqfGKwpK586JPPZYXs0WyBgGIcuXE5uWhq38yDksRQMGkPXIIxiRkZ4JKiIiIh5h+YKyaNGRa4ncc0/Ryb/Z5SLs7beJefRR91D+qFEUDhsGwcGeiigiIiIeZumCYhgwfHgsS5dmnfibysqIePFFoqZOdQ/lPvMMxf37g91eCylFRETE0yxdUEaOjCEgwKBdO+dfvs5WUEDU008T/vbbABjBwRx+9VVKu3fXNUpERES8kGULSnGxjQULwvjuuwNHfd6emUn0uHGEfvABABUNGpD93nuUd+hQlzFFRESkFtRaQVm5ciXvv/8+ubm5NG7cmDvvvJPU1NQTfv/AgbFcdVUJcXGGeyxg925iHnyQ4C++AKD8nHPIXLWKirPP9nh+ERERMU+tnJSxadMm3n77bW666SYmT55M48aNmTRpEnl5eSe8jby8AGbMyMGxdSv1unShwWmnUb9TJ4yQEA5+8QX79+0j+6OPVE5ERER8UK0cQVm+fDmXX345XX+/JPzgwYP55ptvWLduHTfccEOV1zqdTpzOP88xsdlshIaG8uy579Lw+r8DUNKzJ3lDhmBERwNHWpVOd60btt/P4XE4HBiGcZxXS23SXFiH5sI6NBfWEejhm+V6vKBUVFSwe/fuKkXEbrfTqlUrdu7cWe31ixcvZsGCBe7HHTt2ZMSIEVz1Zj+gHwChv3+JeRISEsyOIL/TXFiH5sI6NBfW4XQ6cTgcNd6Oxw9E5Ofn43K5iImJqTIeExNDbm5utdf36tWLmTNnur/69+/PCy+8QElJiaejySkoKSnhoYce0nxYgObCOjQX1qG5sI6SkhJeeOGFKp+K1ITpn5Q4HA7CwsLcX6GhoWzcuFGH6izCMAz27Nmj+bAAzYV1aC6sQ3NhHYZhsHHjRo9tz+MFJSoqCrvdXu1oSW5ubrWjKiIiIiJH4/GCEhgYSNOmTdn2+52BAVwuF9u2baNFixae3p2IiIj4oFpZxdOjRw9eeuklmjZtSmpqKitWrKCsrIwuXboc970Oh4ObbrrJIyfYSM1pPqxDc2Edmgvr0FxYh6fnwmbU0gd3K1euZNmyZeTm5pKSksIdd9xB8+bNa2NXIiIi4mNqraCIiIiInCrTV/GIiIiI/C8VFBEREbEcFRQRERGxHBUUERERsZxaWWZcEytXruT9998nNzeXxo0bc+edd5Kammp2LL+yePFiNm/ezL59+wgKCqJFixb079+fBg0amB3N7y1ZsoTZs2fTrVs3Bg4caHYcv3T48GFmzZrF1q1bKSsrIykpiaFDh9KsWTOzo/kVl8vF/PnzWb9+Pbm5ucTFxdG5c2duvPFG9w0EpXZs376dZcuWsWfPHnJychg9ejQXXHCB+3nDMJg/fz5r166lqKiIli1bctddd5GcnHxS+7HUEZRNmzbx9ttvc9NNNzF58mQaN27MpEmTyMvLMzuaX9m+fTtXX301kyZNYty4cVRWVvLUU09RWlpqdjS/lp6ezurVq2ncuLHZUfxWYWEhjz32GIGBgYwdO5bnn3+e22+/nfDwcLOj+Z0lS5awevVqBg0axPPPP0+/fv1YtmwZH374odnRfF5ZWRkpKSkMGjToqM8vXbqUDz/8kMGDB/P0008THBzMpEmTKC8vP6n9WKqgLF++nMsvv5yuXbvSsGFDBg8eTFBQEOvWrTM7ml959NFH6dKlC6effjopKSkMGzaM7Oxsdu/ebXY0v1VaWsr06dMZMmSIfhmaaOnSpcTHxzN06FBSU1NJTEzk3HPPJSkpyexofmfnzp20a9eO888/n8TERC666CJat25Nenq62dF8Xps2bbj11lurHDX5g2EYrFixgt69e9O+fXsaN27MfffdR05ODlu2bDmp/VimoFRUVLB7925atWrlHrPb7bRq1YqdO3eamEyKi4sBiIiIMDmJ/3r99ddp06YNrVu3NjuKX/vqq69o2rQpU6dO5a677mLMmDGsWbPG7Fh+qUWLFmzbto39+/cDsHfvXnbs2EGbNm1MTubfMjMzyc3NrfJvVVhYGKmpqSf9u9wy56Dk5+fjcrmq3VAwJibG/QModc/lcjFz5kzOOOMMGjVqZHYcv7Rx40b27NnDM888Y3YUv5eZmcnq1avp3r07vXr1YteuXbz55psEBgae0K08xHNuuOEGSkpKuP/++7Hb7bhcLm699VY6depkdjS/9seNgqOjo6uMR0dHV7uJ8PFYpqCINc2YMYNff/2VJ554wuwofik7O5uZM2cybtw4goKCzI7j91wuF82aNeO2224DoEmTJvzyyy+sXr1aBaWOff7552zYsIG0tDROP/109u7dy8yZM4mNjdVc+AjLFJSoqCjsdnu1hpWbm1vtqIrUjRkzZvDNN98wceJE4uPjzY7jl3bv3k1eXh4PPfSQe8zlcvHDDz+wcuVKZs+ejd1umU9qfV5sbCwNGzasMtawYUO+/PJLkxL5r1mzZtGzZ086duwIQKNGjcjKymLJkiUqKCb64/d1Xl4esbGx7vG8vDxSUlJOaluWKSiBgYE0bdqUbdu2uU+8cblcbNu2jWuuucbkdP7FMAzeeOMNNm/ezIQJE0hMTDQ7kt9q1aoVzz33XJWxl19+mQYNGtCzZ0+Vkzp2xhlnVPvIef/+/dSrV8+kRP6rrKys2s+/3W5Ht5czV2JiIjExMXz33XfuQlJcXEx6ejpXXXXVSW3LMgUFoEePHrz00ks0bdqU1NRUVqxYQVlZmdpwHZsxYwYbNmxgzJgxhIaGuo9qhYWF6WOGOhYaGlrt3J/g4GAiIyN1TpAJunfvzmOPPcaiRYvo0KED6enprF27lrvvvtvsaH6nbdu2LFq0iISEBBo2bMjevXtZvnw5Xbt2NTuazystLSUjI8P9ODMzk7179xIREUFCQgLdunVj0aJFJCcnk5iYyNy5c4mNjaV9+/YntR/L3c145cqVLFu2jNzcXFJSUrjjjjto3ry52bH8yi233HLU8aFDh6osWsCECRNISUnRhdpM8vXXXzN79mwyMjJITEyke/fuXHHFFWbH8jslJSXMmzePzZs3k5eXR1xcHB07duSmm24iMNBS//f2Od9//z0TJ06sNt65c2eGDRvmvlDbmjVrKC4upmXLlgwaNOikL/ZpuYIiIiIiog+wRURExHJUUERERMRyVFBERETEclRQRERExHJUUERERMRyVFBERETEclRQRERExHJUUERERMRyVFBERETEclRQRERExHJUUERERMRy/h/BfXXJVHU1oQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "ax = plt.axes()\n",
    "ax.arrow(0.0, 0.0, A[0], A[1], head_width=0.6, head_length=0.5, color = 'red')\n",
    "plt.annotate(f'A({A[0]},{A[1]})', xy=(A[0], A[1]), xytext=(A[0]+0.5, A[1]))\n",
    "ax.arrow(0.0, 0.0, B[0], B[1], head_width=0.4, head_length=0.6, color = 'blue')\n",
    "plt.annotate(f'B({B[0]},{B[1]})', xy=(B[0], B[1]), xytext=(B[0]+0.5, B[1]))\n",
    "plt.xlim(0, 10)\n",
    "plt.ylim(0, 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## コサイン類似度\n",
    "\n",
    "このとき、2つの矢印はそれぞれベクトルを表しています。２つベクトルの近さは、それぞれの矢印の間のコサインで表すことができます。\n",
    "\n",
    "\n",
    "$$\n",
    "\\frac{7 \\times 3 + 3 \\times 7 } { \\sqrt{ 7^2 + 3^2} \\times \\sqrt{3^2 + 7^2}} = 0.7241379\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "もっとも、毎回この計算を行うのは大変です。そこで scikit-learn の **cosine_similarity** を使ってみます。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 3]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(A)\n",
    "## A の次元数\n",
    "print(A.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "## 次元を変換\n",
    "print(A.reshape(1, -1).ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "コサイン類似度:[[0.72413793]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cos_sim = cosine_similarity(A.reshape(1, -1), B.reshape(1, -1))\n",
    "print (f'コサイン類似度:{cos_sim}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "コサイン類似度:[[0.49957554]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([7, 3, 1, 6, 8])\n",
    "B = np.array([3, 7, 2, 1, 0])\n",
    "cos_sim = cosine_similarity(A.reshape(1, -1), B.reshape(1, -1))\n",
    "print (f'コサイン類似度:{cos_sim}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テキストの類似度\n",
    "\n",
    "ところで、文書単語行列では、テキストごとに出現した単語の頻度をベクトルとして表現し、これらを並べて行列として結合したものだと考えることができます。\n",
    "この場合、各文書の次元（ベクトルの要素数）は、すべての文書を通じて出現した語彙数ということになります。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここでも歴代総理大臣所信表明演説データを利用しましょう。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82, 300)\n"
     ]
    }
   ],
   "source": [
    "## data/utf8フォルダにあるファイル一覧を取得\n",
    "import os\n",
    "import re\n",
    "files = ['data/utf8/' + path for path in os.listdir('data/utf8')]\n",
    "pattern = 'data/utf8/\\\\d{8}_(\\\\d{1,3}_[a-z]{1,}-[a-z]{1,})_general-policy-speech.txt'\n",
    "results = [re.match(pattern, file_name) for file_name in files]\n",
    "prime_names = [ res.group(1) for res in results]\n",
    "stopwords = [],\n",
    "with open('data/stopwords.txt', 'r', encoding='utf-8') as f:\n",
    "    stopwords = [w.strip() for w in f]\n",
    "## ストップワードをさらに追加\n",
    "stopwords.extend(['あの', 'この', 'ある', 'する', 'いる', 'できる', 'なる', 'れる', 'の', 'は', '〇', 'ソ', 'もつ', 'わが国', 'われわれ','私たち','そのため','行なう','おこなう','%'])\n",
    "## セットに変更（形態素が重複して登録されているのを避けるため）\n",
    "stopwords = set(stopwords)\n",
    "## ストップワードの要素数を確認\n",
    "len(stopwords)\n",
    "## 単語文書行列の作成\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import my_mecab_stopwords as my_tokenizer\n",
    "args={'stopwords_list': stopwords}\n",
    "vectorizer = CountVectorizer(input='filename', lowercase=False,\n",
    "                             max_df=0.5, max_features=300,\n",
    "                             tokenizer=lambda text: my_tokenizer.tokens(text, **args))\n",
    "prime_dtm = vectorizer.fit_transform(files)\n",
    "## 文書単語行列のサイズを確認\n",
    "print(prime_dtm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "テキスト分析では、文書の長さを合わせることは必ずしも簡単ではありません。そこで、文書の長さに合わせて頻度を調整することを考えます。それが先の章で紹介した TF-IDF ということになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "transformer = TfidfTransformer()\n",
    "## 各ドキュメントのTF-IDFを計算\n",
    "tfidf = transformer.fit_transform(prime_dtm) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         あす      あわせる        いう      かかわる       つくる        とる  \\\n",
      "47_sato-eisaku          0.0  0.075430  0.000000  0.000000  0.000000  0.038310   \n",
      "185_abe-shinzo          0.0  0.135286  0.032800  0.000000  0.152379  0.000000   \n",
      "26_kishi-nobusuke       0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "163_koizumi-jyunichiro  0.0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "49_sato-eisaku          0.0  0.052303  0.000000  0.000000  0.188516  0.053128   \n",
      "...                     ...       ...       ...       ...       ...       ...   \n",
      "81_fukuda-takeo         0.0  0.000000  0.063526  0.065504  0.000000  0.000000   \n",
      "127_hosokawa-morihiro   0.0  0.000000  0.000000  0.000000  0.000000  0.082194   \n",
      "119_kaifu-toshiki       0.0  0.031005  0.060136  0.031005  0.027937  0.062987   \n",
      "149_mori-yoshiro        0.0  0.000000  0.015882  0.016377  0.029514  0.000000   \n",
      "150_mori-yoshiro        0.0  0.000000  0.019097  0.000000  0.053230  0.000000   \n",
      "\n",
      "                             とれる       はかる     ふさわしい       めぐる  ...        重視  \\\n",
      "47_sato-eisaku          0.120628  0.415843  0.000000  0.000000  ...  0.000000   \n",
      "185_abe-shinzo          0.036058  0.000000  0.000000  0.000000  ...  0.000000   \n",
      "26_kishi-nobusuke       0.000000  0.210455  0.000000  0.000000  ...  0.000000   \n",
      "163_koizumi-jyunichiro  0.000000  0.000000  0.000000  0.000000  ...  0.000000   \n",
      "49_sato-eisaku          0.000000  0.230676  0.000000  0.000000  ...  0.000000   \n",
      "...                          ...       ...       ...       ...  ...       ...   \n",
      "81_fukuda-takeo         0.000000  0.000000  0.000000  0.064501  ...  0.000000   \n",
      "127_hosokawa-morihiro   0.043135  0.044610  0.041755  0.000000  ...  0.079678   \n",
      "119_kaifu-toshiki       0.000000  0.000000  0.031998  0.061059  ...  0.000000   \n",
      "149_mori-yoshiro        0.017460  0.000000  0.067607  0.048379  ...  0.000000   \n",
      "150_mori-yoshiro        0.000000  0.000000  0.101611  0.058169  ...  0.000000   \n",
      "\n",
      "                              関心        関連        防止        防衛        需要  \\\n",
      "47_sato-eisaku          0.038310  0.033504  0.035498  0.000000  0.000000   \n",
      "185_abe-shinzo          0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "26_kishi-nobusuke       0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "163_koizumi-jyunichiro  0.000000  0.128816  0.136485  0.000000  0.000000   \n",
      "49_sato-eisaku          0.000000  0.000000  0.000000  0.000000  0.050723   \n",
      "...                          ...       ...       ...       ...       ...   \n",
      "81_fukuda-takeo         0.000000  0.000000  0.000000  0.000000  0.254103   \n",
      "127_hosokawa-morihiro   0.041097  0.000000  0.038081  0.040459  0.000000   \n",
      "119_kaifu-toshiki       0.000000  0.000000  0.000000  0.031005  0.030068   \n",
      "149_mori-yoshiro        0.016635  0.043645  0.030829  0.000000  0.000000   \n",
      "150_mori-yoshiro        0.000000  0.052478  0.018534  0.059074  0.000000   \n",
      "\n",
      "                               韓       高める        高度         ％  \n",
      "47_sato-eisaku          0.131528  0.074275  0.150860  0.000000  \n",
      "185_abe-shinzo          0.000000  0.000000  0.033822  0.069810  \n",
      "26_kishi-nobusuke       0.000000  0.187949  0.000000  0.000000  \n",
      "163_koizumi-jyunichiro  0.000000  0.000000  0.000000  0.000000  \n",
      "49_sato-eisaku          0.121602  0.000000  0.052303  0.000000  \n",
      "...                          ...       ...       ...       ...  \n",
      "81_fukuda-takeo         0.000000  0.000000  0.000000  0.067603  \n",
      "127_hosokawa-morihiro   0.000000  0.119518  0.000000  0.000000  \n",
      "119_kaifu-toshiki       0.036042  0.000000  0.000000  0.000000  \n",
      "149_mori-yoshiro        0.000000  0.016126  0.016377  0.016902  \n",
      "150_mori-yoshiro        0.068672  0.058169  0.019691  0.040644  \n",
      "\n",
      "[82 rows x 300 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/2bddf92b-47f9-4809-95a5-b91e7f25af27/myData/GitHub/myPython/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(tfidf.todense(), columns = vectorizer.get_feature_names(), index = prime_names )\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この文書単語行列の特徴は、文書ごとに長さが1に正規化されていることです。ここで **正規化** とは、各文書の要素をそれぞれ自乗して合計した値の平方根を取ると、1 になっているということです。検算してみましょう。ちなみに、平方根をとるというのは、0.5 乗するということです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47_sato-eisaku            1.0\n",
      "185_abe-shinzo            1.0\n",
      "26_kishi-nobusuke         1.0\n",
      "163_koizumi-jyunichiro    1.0\n",
      "49_sato-eisaku            1.0\n",
      "                         ... \n",
      "81_fukuda-takeo           1.0\n",
      "127_hosokawa-morihiro     1.0\n",
      "119_kaifu-toshiki         1.0\n",
      "149_mori-yoshiro          1.0\n",
      "150_mori-yoshiro          1.0\n",
      "Length: 82, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df.apply(lambda x: (x**2).sum()** 0.5, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "確かに正規化されています。所信表明演説のすべてのペアについて類似度を測ります。これは簡単です。\n",
    "文章単語行列全体に `cosine_similarity()` を適用するだけです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.09230969, 0.20314657, ..., 0.19133002, 0.08584242,\n",
       "        0.15251584],\n",
       "       [0.09230969, 1.        , 0.02794921, ..., 0.23785236, 0.15298248,\n",
       "        0.2556736 ],\n",
       "       [0.20314657, 0.02794921, 1.        , ..., 0.02109276, 0.03230471,\n",
       "        0.10520748],\n",
       "       ...,\n",
       "       [0.19133002, 0.23785236, 0.02109276, ..., 1.        , 0.1656268 ,\n",
       "        0.27399853],\n",
       "       [0.08584242, 0.15298248, 0.03230471, ..., 0.1656268 , 1.        ,\n",
       "        0.69726534],\n",
       "       [0.15251584, 0.2556736 , 0.10520748, ..., 0.27399853, 0.69726534,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prime_sim = cosine_similarity(df)\n",
    "prime_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "例えば1行目の出力の見方は、0番目の所信表明演説(47_sato-eisaku) と 0 番目の所信表明演説の類似度は 1 ということです。つまり、完全に一致しているということになります。これは当然ですね。その横にある 0.30063538 は0番目の所信表明演説と1番目の所信表明演説(185_abe-shinzo)の類似度です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各行ごとに最大値、つまりもっとも類似している所信表明演説を確認してみましょう。なお、各行の最大値は 1 になっています。これは、自分自身との類似度を求めているので、当然です。\n",
    "ちなみに、自分自身との類似度は行列の対角要素になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 行列の対角成分を出力する\n",
    "np.diag(prime_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "単純に各行の最大値を求めてしまうと、自分自身との類似度1が選ばれてしまいます。そこで、この対角要素を `np.fill_diagonal()` で0 に変えてから、最大値を求めることにします。\n",
    "3行3列の行列を例に、この作業のイメージを示しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "行列の対角成分を0に変える\n",
      "[[0 2 3]\n",
      " [4 0 6]\n",
      " [7 8 0]]\n"
     ]
    }
   ],
   "source": [
    "## 単純な行列を作成し\n",
    "A = np.array([[1,2,3], [4,5,6], [7,8,9]])\n",
    "print(A)\n",
    "print('行列の対角成分を0に変える')\n",
    "np.fill_diagonal(A, 0)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "では、文書単語行列の対角成分を0に置き換えてしまいます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.09230969, 0.20314657, ..., 0.19133002, 0.08584242,\n",
       "        0.15251584],\n",
       "       [0.09230969, 0.        , 0.02794921, ..., 0.23785236, 0.15298248,\n",
       "        0.2556736 ],\n",
       "       [0.20314657, 0.02794921, 0.        , ..., 0.02109276, 0.03230471,\n",
       "        0.10520748],\n",
       "       ...,\n",
       "       [0.19133002, 0.23785236, 0.02109276, ..., 0.        , 0.1656268 ,\n",
       "        0.27399853],\n",
       "       [0.08584242, 0.15298248, 0.03230471, ..., 0.1656268 , 0.        ,\n",
       "        0.69726534],\n",
       "       [0.15251584, 0.2556736 , 0.10520748, ..., 0.27399853, 0.69726534,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.fill_diagonal(prime_sim, 0)\n",
    "prime_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "対角成分を確認してみましょう。1行目と1列目、また2行目と2列目の成分を表示してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(prime_sim[0][0])\n",
    "print(prime_sim[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[75 65 71 43 57 31 24 31 45 21 36 16 37 65 16 59 14 22 47 60 53  9 58 30\n",
      " 75 41  9 31 68 48 23 75 71 62 24 49 10 77 37 16 65 25 65 17 38  8 49 53\n",
      " 67 35 80  1 49 56 25 80 53  4 22 56 75 78 33 45 38 42 28 73 73 36  0 32\n",
      " 60 67 61 31  9 37 61 11 55 80]\n"
     ]
    }
   ],
   "source": [
    "row_max_index = np.argmax(prime_sim, axis=1)\n",
    "print(row_max_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "対角要素と、その右上の要素をすべて0に変えます。以下にこの作業のイメージを示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 2 3]\n",
      " [2 0 1]\n",
      " [3 1 0]]\n",
      "右上の要素をすべて0に変える\n",
      "[[0 0 0]\n",
      " [2 0 0]\n",
      " [3 1 0]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[0,2,3], [2,0,1], [3,1,0]])\n",
    "print(A)\n",
    "print('右上の要素をすべて0に変える')\n",
    "A = np.tril(A)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "後の作業のため、ここで所信表明演説の類似度行列のコピーを作成し、このコピーを操作します。いったんデータフレームに変換します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_62015/95743228.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append({'X': prime_names[i] , 'Y': prime_names[j], 'similarity': prime_sim2[i][j] }, ignore_index=True)\n",
      "/tmp/ipykernel_62015/95743228.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append({'X': prime_names[i] , 'Y': prime_names[j], 'similarity': prime_sim2[i][j] }, ignore_index=True)\n",
      "/tmp/ipykernel_62015/95743228.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append({'X': prime_names[i] , 'Y': prime_names[j], 'similarity': prime_sim2[i][j] }, ignore_index=True)\n",
      "/tmp/ipykernel_62015/95743228.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append({'X': prime_names[i] , 'Y': prime_names[j], 'similarity': prime_sim2[i][j] }, ignore_index=True)\n",
      "/tmp/ipykernel_62015/95743228.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append({'X': prime_names[i] , 'Y': prime_names[j], 'similarity': prime_sim2[i][j] }, ignore_index=True)\n",
      "/tmp/ipykernel_62015/95743228.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append({'X': prime_names[i] , 'Y': prime_names[j], 'similarity': prime_sim2[i][j] }, ignore_index=True)\n",
      "/tmp/ipykernel_62015/95743228.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append({'X': prime_names[i] , 'Y': prime_names[j], 'similarity': prime_sim2[i][j] }, ignore_index=True)\n",
      "/tmp/ipykernel_62015/95743228.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append({'X': prime_names[i] , 'Y': prime_names[j], 'similarity': prime_sim2[i][j] }, ignore_index=True)\n",
      "/tmp/ipykernel_62015/95743228.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append({'X': prime_names[i] , 'Y': prime_names[j], 'similarity': prime_sim2[i][j] }, ignore_index=True)\n",
      "/tmp/ipykernel_62015/95743228.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append({'X': prime_names[i] , 'Y': prime_names[j], 'similarity': prime_sim2[i][j] }, ignore_index=True)\n",
      "/tmp/ipykernel_62015/95743228.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append({'X': prime_names[i] , 'Y': prime_names[j], 'similarity': prime_sim2[i][j] }, ignore_index=True)\n",
      "/tmp/ipykernel_62015/95743228.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append({'X': prime_names[i] , 'Y': prime_names[j], 'similarity': prime_sim2[i][j] }, ignore_index=True)\n",
      "/tmp/ipykernel_62015/95743228.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append({'X': prime_names[i] , 'Y': prime_names[j], 'similarity': prime_sim2[i][j] }, ignore_index=True)\n",
      "/tmp/ipykernel_62015/95743228.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append({'X': prime_names[i] , 'Y': prime_names[j], 'similarity': prime_sim2[i][j] }, ignore_index=True)\n",
      "/tmp/ipykernel_62015/95743228.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append({'X': prime_names[i] , 'Y': prime_names[j], 'similarity': prime_sim2[i][j] }, ignore_index=True)\n",
      "/tmp/ipykernel_62015/95743228.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append({'X': prime_names[i] , 'Y': prime_names[j], 'similarity': prime_sim2[i][j] }, ignore_index=True)\n",
      "/tmp/ipykernel_62015/95743228.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append({'X': prime_names[i] , 'Y': prime_names[j], 'similarity': prime_sim2[i][j] }, ignore_index=True)\n",
      "/tmp/ipykernel_62015/95743228.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append({'X': prime_names[i] , 'Y': prime_names[j], 'similarity': prime_sim2[i][j] }, ignore_index=True)\n",
      "/tmp/ipykernel_62015/95743228.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append({'X': prime_names[i] , 'Y': prime_names[j], 'similarity': prime_sim2[i][j] }, ignore_index=True)\n",
      "/tmp/ipykernel_62015/95743228.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append({'X': prime_names[i] , 'Y': prime_names[j], 'similarity': prime_sim2[i][j] }, ignore_index=True)\n",
      "/tmp/ipykernel_62015/95743228.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append({'X': prime_names[i] , 'Y': prime_names[j], 'similarity': prime_sim2[i][j] }, ignore_index=True)\n",
      "/tmp/ipykernel_62015/95743228.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append({'X': prime_names[i] , 'Y': prime_names[j], 'similarity': prime_sim2[i][j] }, ignore_index=True)\n",
      "/tmp/ipykernel_62015/95743228.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append({'X': prime_names[i] , 'Y': prime_names[j], 'similarity': prime_sim2[i][j] }, ignore_index=True)\n",
      "/tmp/ipykernel_62015/95743228.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append({'X': prime_names[i] , 'Y': prime_names[j], 'similarity': prime_sim2[i][j] }, ignore_index=True)\n",
      "/tmp/ipykernel_62015/95743228.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append({'X': prime_names[i] , 'Y': prime_names[j], 'similarity': prime_sim2[i][j] }, ignore_index=True)\n",
      "/tmp/ipykernel_62015/95743228.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append({'X': prime_names[i] , 'Y': prime_names[j], 'similarity': prime_sim2[i][j] }, ignore_index=True)\n",
      "/tmp/ipykernel_62015/95743228.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append({'X': prime_names[i] , 'Y': prime_names[j], 'similarity': prime_sim2[i][j] }, ignore_index=True)\n",
      "/tmp/ipykernel_62015/95743228.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append({'X': prime_names[i] , 'Y': prime_names[j], 'similarity': prime_sim2[i][j] }, ignore_index=True)\n",
      "/tmp/ipykernel_62015/95743228.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append({'X': prime_names[i] , 'Y': prime_names[j], 'similarity': prime_sim2[i][j] }, ignore_index=True)\n",
      "/tmp/ipykernel_62015/95743228.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append({'X': prime_names[i] , 'Y': prime_names[j], 'similarity': prime_sim2[i][j] }, ignore_index=True)\n",
      "/tmp/ipykernel_62015/95743228.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append({'X': prime_names[i] , 'Y': prime_names[j], 'similarity': prime_sim2[i][j] }, ignore_index=True)\n",
      "/tmp/ipykernel_62015/95743228.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append({'X': prime_names[i] , 'Y': prime_names[j], 'similarity': prime_sim2[i][j] }, ignore_index=True)\n",
      "/tmp/ipykernel_62015/95743228.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append({'X': prime_names[i] , 'Y': prime_names[j], 'similarity': prime_sim2[i][j] }, ignore_index=True)\n",
      "/tmp/ipykernel_62015/95743228.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append({'X': prime_names[i] , 'Y': prime_names[j], 'similarity': prime_sim2[i][j] }, ignore_index=True)\n",
      "/tmp/ipykernel_62015/95743228.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append({'X': prime_names[i] , 'Y': prime_names[j], 'similarity': prime_sim2[i][j] }, ignore_index=True)\n",
      "/tmp/ipykernel_62015/95743228.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append({'X': prime_names[i] , 'Y': prime_names[j], 'similarity': prime_sim2[i][j] }, ignore_index=True)\n",
      "/tmp/ipykernel_62015/95743228.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append({'X': prime_names[i] , 'Y': prime_names[j], 'similarity': prime_sim2[i][j] }, ignore_index=True)\n",
      "/tmp/ipykernel_62015/95743228.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df2 = df2.append({'X': prime_names[i] , 'Y': prime_names[j], 'similarity': prime_sim2[i][j] }, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>57_sato-eisaku</td>\n",
       "      <td>62_sato-eisaku</td>\n",
       "      <td>0.848907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>59_sato-eisaku</td>\n",
       "      <td>57_sato-eisaku</td>\n",
       "      <td>0.782025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>178_noda-yoshihiko</td>\n",
       "      <td>179_noda-yoshihiko</td>\n",
       "      <td>0.772783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>168_fukuda-yasuo</td>\n",
       "      <td>168_abe-shinzo</td>\n",
       "      <td>0.726031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>149_mori-yoshiro</td>\n",
       "      <td>146_obuchi-keizo</td>\n",
       "      <td>0.722004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>144_obuchi-keizo</td>\n",
       "      <td>143_obuchi-keizo</td>\n",
       "      <td>0.702743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>150_mori-yoshiro</td>\n",
       "      <td>149_mori-yoshiro</td>\n",
       "      <td>0.697265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>127_hosokawa-morihiro</td>\n",
       "      <td>128_hosokawa-morihiro</td>\n",
       "      <td>0.683462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>88_ohira-masayoshi</td>\n",
       "      <td>90_ohira-masayoshi</td>\n",
       "      <td>0.666702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>141_hashimoto-ryutaro</td>\n",
       "      <td>139_hashimoto-ryutaro</td>\n",
       "      <td>0.647692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>50_sato-eisaku</td>\n",
       "      <td>49_sato-eisaku</td>\n",
       "      <td>0.638764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>187_abe-shinzo</td>\n",
       "      <td>185_abe-shinzo</td>\n",
       "      <td>0.621897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>81_fukuda-takeo</td>\n",
       "      <td>82_fukuda-takeo</td>\n",
       "      <td>0.620922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>131_murayama-tomiichi</td>\n",
       "      <td>134_murayama-tomiichi</td>\n",
       "      <td>0.615614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>93_suzuki-zenko</td>\n",
       "      <td>88_ohira-masayoshi</td>\n",
       "      <td>0.614568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>41_ikeda-hayato</td>\n",
       "      <td>44_ikeda-hayato</td>\n",
       "      <td>0.607715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>125_miyazawa-kiichi</td>\n",
       "      <td>122_miyazawa-kiichi</td>\n",
       "      <td>0.605454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>151_koizumi-jyunichiro</td>\n",
       "      <td>153_koizumi-jyunichiro</td>\n",
       "      <td>0.597299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>107_nakasone-yasuhiro</td>\n",
       "      <td>103_nakasone-yasuhiro</td>\n",
       "      <td>0.596132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>129_hata-tsutomu</td>\n",
       "      <td>131_murayama-tomiichi</td>\n",
       "      <td>0.583831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         X                       Y  similarity\n",
       "16          57_sato-eisaku          62_sato-eisaku    0.848907\n",
       "19          59_sato-eisaku          57_sato-eisaku    0.782025\n",
       "23      178_noda-yoshihiko      179_noda-yoshihiko    0.772783\n",
       "29        168_fukuda-yasuo          168_abe-shinzo    0.726031\n",
       "36        149_mori-yoshiro        146_obuchi-keizo    0.722004\n",
       "8         144_obuchi-keizo        143_obuchi-keizo    0.702743\n",
       "37        150_mori-yoshiro        149_mori-yoshiro    0.697265\n",
       "34   127_hosokawa-morihiro   128_hosokawa-morihiro    0.683462\n",
       "11      88_ohira-masayoshi      90_ohira-masayoshi    0.666702\n",
       "3    141_hashimoto-ryutaro   139_hashimoto-ryutaro    0.647692\n",
       "17          50_sato-eisaku          49_sato-eisaku    0.638764\n",
       "13          187_abe-shinzo          185_abe-shinzo    0.621897\n",
       "33         81_fukuda-takeo         82_fukuda-takeo    0.620922\n",
       "12   131_murayama-tomiichi   134_murayama-tomiichi    0.615614\n",
       "21         93_suzuki-zenko      88_ohira-masayoshi    0.614568\n",
       "31         41_ikeda-hayato         44_ikeda-hayato    0.607715\n",
       "20     125_miyazawa-kiichi     122_miyazawa-kiichi    0.605454\n",
       "18  151_koizumi-jyunichiro  153_koizumi-jyunichiro    0.597299\n",
       "5    107_nakasone-yasuhiro   103_nakasone-yasuhiro    0.596132\n",
       "14        129_hata-tsutomu   131_murayama-tomiichi    0.583831"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(prime_sim))\n",
    "prime_sim2 =  np.tril(prime_sim)\n",
    "df2 = pd.DataFrame(columns=['X', 'Y', 'similarity'])\n",
    "\n",
    "for i, j in enumerate(row_max_index):\n",
    "    if prime_sim2[i][j] == 0:\n",
    "        continue\n",
    "    else:\n",
    "        df2 = df2.append({'X': prime_names[i] , 'Y': prime_names[j], 'similarity': prime_sim2[i][j] }, ignore_index=True)\n",
    "df2.sort_values('similarity', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ペアの類似度が高いのは、ほとんどが同じ総理大臣による（別の国会での別の）演説となっています。これは互いに内容が似ているのも当然でしょう。また、異なる総理大臣による所信表明演説が高い類似度を示している場合は、時代間隔（国会の開催年月日）がきわめて近いことも確認できます。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "たとえば、安倍晋三氏は 168 期の国会で退陣し、その 5 年後に再び総理大臣に返り咲いています。つまり最初の就任期と、第183回との間には時間的なズレがあり、そのため演説の内容やスタンスも変わっていると思われます。確認してみましょう。最初に作成した `prime_sim` から検索します。 ただし、この配列には行名（また列名）がないので、いったんデータフレームに変換しましょう。この結果を `filter()` を使って絞り込みます。まず index に `abe` が含まれている行を抽出し、続けて列名に `abe` が含まれている列を探します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>185_abe-shinzo</th>\n",
       "      <th>183_abe-shinzo</th>\n",
       "      <th>165_abe-shinzo</th>\n",
       "      <th>187_abe-shinzo</th>\n",
       "      <th>168_abe-shinzo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>165_abe-shinzo</th>\n",
       "      <td>0.312261</td>\n",
       "      <td>0.382760</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.361620</td>\n",
       "      <td>0.567292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168_abe-shinzo</th>\n",
       "      <td>0.280728</td>\n",
       "      <td>0.375282</td>\n",
       "      <td>0.567292</td>\n",
       "      <td>0.321299</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183_abe-shinzo</th>\n",
       "      <td>0.462252</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.382760</td>\n",
       "      <td>0.443823</td>\n",
       "      <td>0.375282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185_abe-shinzo</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.462252</td>\n",
       "      <td>0.312261</td>\n",
       "      <td>0.621897</td>\n",
       "      <td>0.280728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187_abe-shinzo</th>\n",
       "      <td>0.621897</td>\n",
       "      <td>0.443823</td>\n",
       "      <td>0.361620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.321299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                185_abe-shinzo  183_abe-shinzo  165_abe-shinzo  \\\n",
       "165_abe-shinzo        0.312261        0.382760        0.000000   \n",
       "168_abe-shinzo        0.280728        0.375282        0.567292   \n",
       "183_abe-shinzo        0.462252        0.000000        0.382760   \n",
       "185_abe-shinzo        0.000000        0.462252        0.312261   \n",
       "187_abe-shinzo        0.621897        0.443823        0.361620   \n",
       "\n",
       "                187_abe-shinzo  168_abe-shinzo  \n",
       "165_abe-shinzo        0.361620        0.567292  \n",
       "168_abe-shinzo        0.321299        0.000000  \n",
       "183_abe-shinzo        0.443823        0.375282  \n",
       "185_abe-shinzo        0.621897        0.280728  \n",
       "187_abe-shinzo        0.000000        0.321299  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.DataFrame(prime_sim, columns=prime_names, index=prime_names)\n",
    "df3.filter(like = 'abe', axis=0).filter(regex='abe').sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "出力が分かりにくいかと思いますが、例えば1行目 (165_abe-shinzo) は第165回国会での所信表明演説にあたり、その内容について第1列目(165_abe-shinzo)、すなわち第185回演説との近さを測ると約 32％となっています。一方、3列めの第165回演説との類似度は1ということです。つまり、完全に一致しているということになります。これは当然ですね。その横にある 0.51687549 は1番目の所信表明演説と2番目の所信表明演説(168_abe-shinzo )の類似度です。ちなみに安倍元総理は、この段階で退陣し、5年後に再び総理大臣に返り咲いています。つまり最初の就任期と、第183回との間には時間的なズレがあり、そのため演説の内容やスタンスも変わっていると思われます。実際、時間的に離れた所信表明演説の類似度は小さくなっているようです。\n",
    "\n",
    "165 期と 168 期の演説の類似度は約 0.495 です。また 183 期以降の演説それぞれの類似度はそれぞれ 0.5 を超えています。が、165 期ないし 168 期の演説と、183 期以降の演説との類似度は 0.2 から 0.3 のあいだとなっています。\n",
    "\n",
    "一方、181 期の旧民主党の野田元総理と 185 期の自民党安倍元総理の類似度が 0.67 と高いことに気が付きます。\n",
    "参考までに文書単語行列に登録された単語の一覧をみてみましょう。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['あす', 'あわせる', 'いう', 'かかわる', 'つくる', 'とる', 'とれる', 'はかる', 'ふさわしい', 'めぐる', 'もたらす', 'よい', 'エネルギー', 'サミット', 'サービス', 'システム', 'テロ', '一体', '一端', '上げる', '上昇', '不可欠', '世代', '中央', '主要', '予定', '事件', '事実', '事態', '事故', '交換', '交流', '人口', '人材', '人間', '人類', '介護', '仕事', '会談', '住宅', '住民', '使命', '供給', '依存', '価値', '価格', '保険', '個人', '倫理', '働く', '先進', '克服', '全国', '公債', '公正', '共通', '内容', '内政', '円滑', '再建', '再生', '処理', '分権', '利用', '制', '削減', '前進', '割り', '創造', '力強い', '労働', '動き', '動向', '北朝鮮', '医療', '協議', '南北', '危機', '参加', '収支', '取りまとめる', '取り戻す', '取り組み', '受けとめる', '合う', '合意', '合理', '向かう', '含む', '含める', '国交', '国土', '国連', '土地', '地球', '均衡', '型', '基礎', '基調', '基軸', '堅持', '増加', '声', '変革', '外国', '多様', '大切', '大幅', '大胆', '大震災', '太平洋', '委員', '姿', '姿勢', '子供', '存じる', '学校', '安心', '家庭', '寄与', '対外', '対話', '導入', '展望', '展開', '市場', '幅広い', '平成', '年代', '年金', '年間', '引き続く', '形成', '役', '役割', '従来', '復旧', '復興', '徹底', '応じる', '思い', '急速', '情報', '意味', '憲法', '懸案', '戦略', '所存', '所得', '払う', '抜本', '担う', '拉致', '拡充', '挙げる', '提案', '支える', '支持', '改正', '政党', '政権', '断行', '新生', '方向', '施設', '日本人', '明るい', '明確', '昨年', '昭和', '是正', '最大', '最大限', '本格', '来年', '東京', '枠組み', '柱', '核', '案', '構想', '構築', '機関', '次第', '歩', '歳出', '残す', '民族', '水準', '沖', '沖縄', '法人', '法律', '活性', '深刻', '減税', '準備', '物価', '特別', '率直', '現実', '理念', '生かす', '生きる', '生じる', '申す', '発揮', '発生', '皆さん', '皆様', '省庁', '真', '真剣', '石油', '研究', '確信', '確実', '確認', '福島', '科学', '秩序', '税', '競争', '答申', '策定', '管理', '紛争', '経営', '経験', '継続', '続く', '緊張', '緊急', '締結', '編成', '繩', '置く', '考え方', '育成', '能力', '臨む', '臨時', '自立', '至る', '若者', '行動', '行財政', '被害', '被災', '補正', '要請', '見直す', '視点', '視野', '言う', '許す', '訴える', '評価', '調和', '調整', '調査', '諸君', '講ずる', '議論', '財源', '費', '資本', '資源', '資金', '質', '超える', '転換', '輸入', '輸出', '農林', '農業', '近代', '述べる', '途上', '通常', '速やか', '連携', '進展', '遂げる', '過去', '選挙', '都市', '配慮', '重ねる', '重点', '重視', '関心', '関連', '防止', '防衛', '需要', '韓', '高める', '高度', '％']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/2bddf92b-47f9-4809-95a5-b91e7f25af27/myData/GitHub/myPython/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "安倍総理の演説における「復興」と「被災地」の出現確率を確認します。（「復興」あるいは「被災地」が、いずれのトピックでも上位語に含まれていない場合があります。その場合は、上の出力を参考に適宜、単語を変更してください）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>復興</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>185_abe-shinzo</th>\n",
       "      <td>0.141890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183_abe-shinzo</th>\n",
       "      <td>0.260913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165_abe-shinzo</th>\n",
       "      <td>0.061723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187_abe-shinzo</th>\n",
       "      <td>0.149475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168_abe-shinzo</th>\n",
       "      <td>0.043414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      復興\n",
       "185_abe-shinzo  0.141890\n",
       "183_abe-shinzo  0.260913\n",
       "165_abe-shinzo  0.061723\n",
       "187_abe-shinzo  0.149475\n",
       "168_abe-shinzo  0.043414"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.filter(like='abe', axis=0)[['復興', '被災地']]\n",
    "df.filter(like='abe', axis=0)[['復興']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>復興</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>181_noda-yoshihiko</th>\n",
       "      <td>0.138565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179_noda-yoshihiko</th>\n",
       "      <td>0.344189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178_noda-yoshihiko</th>\n",
       "      <td>0.189230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          復興\n",
       "181_noda-yoshihiko  0.138565\n",
       "179_noda-yoshihiko  0.344189\n",
       "178_noda-yoshihiko  0.189230"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.filter(like='noda', axis=0)[['復興', '被災地']]\n",
    "df.filter(like='noda', axis=0)[['復興']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 単語分散表現\n",
    "\n",
    "前章までは、テキストから BoW を作成していました。BoW をベースにしたモデルでは、文書ごとに形態素（単語）の出現回数を調べ、必要に応じて頻度を TF-IDF などに変換したデータを分析の出発点とします。\n",
    "この場合、形態素が出現した位置、あるいは文脈（その形態素が、別のどのような形態素の後ないし前に出現したのか）は考慮されていません。\n",
    "\n",
    "しかしながら、文章においては、形態素が文中のどこに出現しているかは非常に重要です。ある形態素がどの位置に出現するかは、まず文章全体によって決まります。つまり、出現位置は、文章の意味と深く関わっています。形態素の多くは特定の文脈に現れることから、同じような文脈に表れる形態素の意味は似ているとする仮説があります。たとえば以下の2つの文は、同じような文脈を表しています。\n",
    "\n",
    "1. 校庭 で サッカー を した。\n",
    "2. 校庭 で 野球 を した。\n",
    "\n",
    "サッカーと野球は似て非なるもののですが、ボールを使う球技で人間が「する」ものであり、かつ校庭にような広いスペースを必要とするという共通点があります。\n",
    "出現する文脈が似ている場合、その意味も似ていると考えるのが、**分布仮説** です。そこで、大量のテキストから、ある形態素がどのような文脈で出現したかを調べれば、分布の似ている形態素を知ることができます。そこで、ある形態素の意味を、近隣に出現しやすい形態素との近さとして表現できると便利です。\n",
    "\n",
    "\n",
    "\n",
    "## Word2Vec\n",
    "\n",
    "**単語分散表現** の嚆矢である Word2Vec では、大規模なテキスト集合であるコーパスから単語分散表現を作成します。\n",
    "この際には主に2つの方法が使われています。\n",
    "1つは、ある特定の文脈に出現しやすい単語を予測できるようなモデルを生成することです。\n",
    "もう1つは、ある単語の周辺に出現しやすい単語群を予測できるようなモデルを生成することになります。\n",
    "前者を CBOW, 後者を **skip-gram** と呼びます。 \n",
    "\n",
    "いずれも方法でも、入力となるのは単語の **ワンホットベクトル** です。\n",
    "\n",
    "\n",
    "### ワンホットベクトル\n",
    "\n",
    "いま、出現する語が「犬」「猫」「猿」「雉」「人」の5つだけのテキストがあるとします。\n",
    "このとき、「犬」を次のベクトルで表現します。このとき、それぞれの単語を次のベクトルで表現します。行列の列（縦）が各単語のベクトルになります。\n",
    "\n",
    "| 犬 | 猫 | 猿 | 雉 | 人 | \n",
    "|---|---|---|--|---|\n",
    "| 1 | 0 | 0 | 0 | 0 |\n",
    "| 0 | 1 | 0 | 0 | 0 |\n",
    "| 0 | 0 | 1 | 0 | 0 |\n",
    "| 0 | 0 | 0 | 1 | 0 |\n",
    "| 0 | 0 | 0 | 0 | 1 |\n",
    "\n",
    "要は、行ごとにみると1行名が「犬要素」、2行目が「猫要素」、3行目が「猿要素」、4行目が「雉要素」、5行目が「人要素」に対応しているわけです。\n",
    "そして1列目の犬は、5行のうち該当するのが1行目だけであり、ここを 1 とし、ほかがすべて0になります。\n",
    "単純ですが、これにより各単語が 5 次元のベクトルで表され、互いに区別できるわけです。\n",
    "\n",
    "ただし、読者の中には、猿と人は近いから、猿ベクトルと人ベクトルは、「猿要素」と「犬要素」の両方に反応しても良いのではないかと思う方も要るかもしれません。\n",
    "\n",
    "| 犬 | 猫 | 猿 | 雉 | 人 | \n",
    "|---|---|---|--|---|\n",
    "| 1 | 0 | 0 | 0 | 0 |\n",
    "| 0 | 1 | 0 | 0 | 0 |\n",
    "| 0 | 0 | 1 | 0 | 1 |\n",
    "| 0 | 0 | 0 | 1 | 0 |\n",
    "| 0 | 0 | 1 | 0 | 1 |\n",
    "\n",
    "ただ、こうすると「猿」と「人」のベクトルがまったく同じなって区別がつきません。\n",
    "そこで、たとえば次のようにして、「人」は「人要素」が強く、「猿要素」は弱いが、「猿」は逆であることを示す頃ができるかもしれません。\n",
    "\n",
    "\n",
    "| 犬 | 猫 | 猿 | 雉 | 人 | \n",
    "|---|---|---|--|---|\n",
    "| 1 | 0 | 0 | 0 | 0 |\n",
    "| 0 | 1 | 0 | 0 | 0 |\n",
    "| 0 | 0 | 0.8 | 0 | 0.1 |\n",
    "| 0 | 0 | 0 | 1 | 0 |\n",
    "| 0 | 0 | 0.2 | 0 | 0.9 |\n",
    "\n",
    "単語を複数次元のベクトルで表すということは、このように単語と単語の違いに加えて、その近さ（類似度）を表現することでもあります。\n",
    "上で猿ベクトルと人ベクトルの数値は適当に決めましたが、これらを大規模テキストデータを使って計算しようというのが、ここで紹介するワードベクトルになります。\n",
    "\n",
    "\n",
    "### skip-gram\n",
    "\n",
    "東北大学の乾・岡崎研究室 [^tohoku_uni] では、研究過程で作成した単語分散表現を公開しています。\n",
    "以下、本書でも、このモデルを利用させてもらいます。\n",
    "\n",
    "[^tohoku_uni]: <https://www.nlp.ecei.tohoku.ac.jp/> <http://www.cl.ecei.tohoku.ac.jp/~m-suzuki/jawiki_vector/>\n",
    "\n",
    "\n",
    "ダウンロードした単語分散表現を扱うために Python に **gensim** ライブラリを導入します。\n",
    "\n",
    "`pip install gensim`\n",
    "\n",
    "準備が整いましたので、ダウンロードした単語分散表現を使ってみましょう。\n",
    "\n",
    "なお、gensim は Anaconda には付属していません。別途 `pip` でインストールしてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.0/24.0 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /mnt/2bddf92b-47f9-4809-95a5-b91e7f25af27/myData/GitHub/myPython/lib/python3.10/site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /mnt/2bddf92b-47f9-4809-95a5-b91e7f25af27/myData/GitHub/myPython/lib/python3.10/site-packages (from gensim) (1.9.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /mnt/2bddf92b-47f9-4809-95a5-b91e7f25af27/myData/GitHub/myPython/lib/python3.10/site-packages (from gensim) (1.23.2)\n",
      "Installing collected packages: gensim\n",
      "Successfully installed gensim-4.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "## ダウンロードした単語分散表現が Jupyter を起動しているフォルダにあるとします\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('entity_vector.model.bin', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここで利用するのモデルはファイル名の末尾が bin となっています\n",
    "これを使って、「徳島」がここでどのように表現されているかを確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.1451146   0.64631635  1.1206466   0.53557366  1.1265059  -0.47855055\n",
      " -1.9572403  -0.36092016 -0.12230052  0.00528774 -0.9410112   0.5655498\n",
      " -0.34019628  0.03107905  1.2963295  -0.03178046  0.67060477  1.1305983\n",
      " -0.3368416  -1.2133294   1.1458337  -1.2171845   1.3975791  -0.8819545\n",
      "  0.8784004  -1.0548002  -1.2283356   0.04045669 -0.01702263 -0.32386667\n",
      " -1.0599047   0.8248806   0.12551713 -0.12358826  2.4171948   0.5412358\n",
      "  1.6744537   0.7213261  -0.07311266  1.221979    0.60591567  0.6359788\n",
      " -1.6467801  -0.483416    0.33695164  0.52571183 -0.8949706   0.6989222\n",
      "  0.10594787  1.4380262   2.4102638  -1.5664365  -0.1476826  -1.0740054\n",
      "  0.13817035  0.28903145  1.1353608   0.02972492  0.42153484  0.3525321\n",
      "  0.41672072  0.45877242 -1.367437   -1.2573254   0.44229034  1.6489668\n",
      " -0.5580291   1.5877541   0.45503724  0.41794908 -0.48812628 -0.75694937\n",
      "  0.16592807  0.21474564 -0.39681706  0.40212667 -0.72284573 -1.7669711\n",
      " -0.71841913 -0.3941651   1.3607436   1.4318576   0.43657574 -1.0812192\n",
      " -1.4796697   0.8808305  -2.896217   -0.28217202 -0.10230227 -1.8142314\n",
      " -0.7627604   0.61423904 -0.407716    0.9422217  -1.2616667   2.3023157\n",
      " -2.4974165   0.33682728  0.31226307 -1.6989379  -0.612968    0.9000666\n",
      " -0.79090774 -0.42063704  0.19587651 -0.02609681 -0.40632007 -0.14033686\n",
      " -0.30916756  0.0440501   0.26087508 -0.5646983  -1.0106723  -1.3726658\n",
      " -0.24852811 -1.0716788  -0.04256602 -0.15830214 -0.14624959  1.3771601\n",
      "  0.78676933  1.7137731  -0.7104532   0.01694393  0.698215    0.20814341\n",
      " -0.47401345 -1.3165212  -0.30451518 -0.33904967  0.67839813  0.07755331\n",
      " -0.07964803 -1.2001079  -1.3295679  -0.20558964  1.2172337   0.9167497\n",
      "  0.24913028  1.266321   -0.71333826  2.1852624  -0.07494659 -1.30173\n",
      " -0.22887936  0.35512725  0.7201695   0.53420866  0.18403317  2.0518787\n",
      " -0.6226907  -0.37034342  0.2113158  -1.022931   -1.2034961  -1.6787721\n",
      "  0.34630585 -2.0976436   0.30796668 -0.29899076 -0.1294589  -0.34831455\n",
      "  0.2448933  -0.312876    0.5916982  -1.3266097   0.67156494  0.8034996\n",
      "  0.5298861   0.95500755  1.0610118   1.1583117   0.40923405 -0.23056316\n",
      " -1.4721186   2.5312393  -0.24470648  0.7045202   1.8048768   0.01326977\n",
      "  2.409381    1.6333113  -0.98599666 -0.17802572  0.03622497 -0.16439998\n",
      "  0.11351351 -1.5526029  -0.4652032   0.72413975 -1.8166566   1.4446893\n",
      " -1.3221014   0.9393928   1.338765    0.40931824 -0.23101576 -3.3050535\n",
      "  0.58510953  0.02195218]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model['徳島'])\n",
    "model['徳島'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('香川県', 0.8651489615440369),\n",
       " ('岡山県', 0.8528105616569519),\n",
       " ('山口県', 0.8483657240867615),\n",
       " ('愛媛県', 0.8469836711883545),\n",
       " ('高知県', 0.8455371856689453),\n",
       " ('熊本県', 0.8427625894546509),\n",
       " ('新潟県', 0.8358582258224487),\n",
       " ('島根県', 0.8284846544265747),\n",
       " ('鳥取県', 0.8260581493377686),\n",
       " ('静岡県', 0.8161298632621765)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('徳島県')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上位 5 つは、要するに中国・四国地方に位置する県になっています。他に、熊本や新潟が似ていると判断されています。\n",
    "\n",
    "もう少し、単語分散表現で遊んでみましょう。単語分散表現で話題によく上がるのが、概念を計算できることです。「東京」から「日本」を引いて、「フランス」を足すという操作ができるのです。\n",
    "\n",
    "`東京 - 日本 + フランス`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('パリ', 0.7462971210479736),\n",
       " ('[パリ]', 0.6993756294250488),\n",
       " ('ベルリン', 0.6419284343719482),\n",
       " ('ロンドン', 0.6390188336372375),\n",
       " ('ミラノ', 0.6374871730804443),\n",
       " ('ウィーン', 0.6211003065109253),\n",
       " ('ブリュッセル', 0.6124843955039978),\n",
       " ('ミュンヘン', 0.6093114614486694),\n",
       " ('ハンブルク', 0.5993486642837524),\n",
       " ('[リヨン]', 0.5960404872894287)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['東京', 'フランス'], negative=['日本'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "次に、「阿波おどり」から「徳島」を引いて、高知を足してみましょう。\n",
    "\n",
    "`阿波おどり - 徳島 + 高知`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('[よさこい]', 0.6300591230392456),\n",
       " ('夏祭り', 0.5732635259628296),\n",
       " ('[よさこい祭り]', 0.5656487941741943),\n",
       " ('[YOSAKOI]', 0.5619512796401978),\n",
       " ('夏まつり', 0.5619202256202698),\n",
       " ('総踊り', 0.5596013069152832),\n",
       " ('夏祭', 0.5583030581474304),\n",
       " ('[阿波踊り]', 0.5561996102333069),\n",
       " ('おどり', 0.548295259475708),\n",
       " ('まつり', 0.5472521185874939)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['阿波おどり', '高知'], negative=['徳島'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "「よさこい」がもっともらしいと出ました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['徳島', '阿波', '踊り', '見学', 'する']\n",
      "['青森', 'ねぶた', '祭', '観る']\n",
      "['福岡', '豚', '骨', 'ラーメン', '食べる']\n"
     ]
    }
   ],
   "source": [
    "import my_janome_stopwords as jnm\n",
    "text1 = jnm.tokens('徳島で、阿波踊りを見学した')\n",
    "print(text1)\n",
    "text2 = jnm.tokens('青森で、ねぶた祭を観た')\n",
    "print(text2)\n",
    "text3 = jnm.tokens('福岡で、豚骨ラーメンを食べた')\n",
    "print(text3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それぞれの文章から抽出された形態素は、いずれもが 200 次元のベクトルで表現されています。\n",
    "\n",
    "\n",
    "ある文章が3つの形態素からなっていたとします。この形態素をそれぞれ word1,word2,word3 とします。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "word1 = np.array([1,2,3,4,5])\n",
    "word2 = np.array([5,4,3,2,1])\n",
    "word3 = np.array([1,0,2,0,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.33333333, 2.        , 2.66666667, 2.        , 3.        ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = word1 + word2 + word3\n",
    "words / 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "つまり、この3語からなる文章を 5 次元のベクトルに表現することができました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_vec(word_list, model):\n",
    "    ## 計算結果を蓄積する空のベクトルを用意しておく\n",
    "    vec_ = np.zeros((200,), dtype='float32') \n",
    "    for word in word_list:\n",
    "        vec_ = np.add(vec_, model[word])\n",
    "    if len(word_list) > 0:\n",
    "        vec_ = np.divide(vec_, len(word_list))\n",
    "    return vec_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg1 = avg_vec(text1, model)\n",
    "avg2 = avg_vec(text2, model)\n",
    "avg3 = avg_vec(text3, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前回と同じ方法でコサイン距離を求めます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "コサイン類似度: txt1 vs txt2 :[[0.5231217]]\n",
      "コサイン類似度: txt1 vs txt3 :[[0.46388638]]\n",
      "コサイン類似度: txt2 vs txt3 :[[0.3673437]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cos_sim1 = cosine_similarity(avg1.reshape(1, -1), avg2.reshape(1, -1))\n",
    "print (f'コサイン類似度: txt1 vs txt2 :{cos_sim1}')\n",
    "cos_sim2 = cosine_similarity(avg1.reshape(1, -1), avg3.reshape(1, -1))\n",
    "print (f'コサイン類似度: txt1 vs txt3 :{cos_sim2}')\n",
    "cos_sim3 = cosine_similarity(avg2.reshape(1, -1), avg3.reshape(1, -1))\n",
    "print (f'コサイン類似度: txt2 vs txt3 :{cos_sim3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('[エッフェル塔]', 0.5456256866455078),\n",
       " ('マドリッド', 0.5358479022979736),\n",
       " ('[シャンゼリゼ通り]', 0.49942439794540405),\n",
       " ('[トラファルガー広場]', 0.49436208605766296),\n",
       " ('[リール_(フランス)]', 0.49335700273513794),\n",
       " ('ヴィラ', 0.4929209351539612),\n",
       " ('[エトワール凱旋門]', 0.49175509810447693),\n",
       " ('[パレ・ロワイヤル]', 0.49152642488479614),\n",
       " ('ナポリ', 0.49030327796936035),\n",
       " ('シャトー', 0.488348126411438)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## スカイツリ - 日本 + フランス\n",
    "model.most_similar(positive=['スカイツリー', 'フランス'], negative=['日本'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('[日本茶]', 0.6305805444717407),\n",
       " ('[泡盛]', 0.6159665584564209),\n",
       " ('[日本酒]', 0.5956202149391174),\n",
       " ('[清酒]', 0.5938064455986023),\n",
       " ('焼酎', 0.5927814841270447),\n",
       " ('[焼酎]', 0.5906597375869751),\n",
       " ('清酒', 0.5873808860778809),\n",
       " ('地酒', 0.5791105031967163),\n",
       " ('日本酒', 0.5710263848304749),\n",
       " ('[納豆]', 0.5674401521682739)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ワイン - フランス + 日本 \n",
    "model.most_similar(positive=['ワイン', '日本'], negative=['フランス'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "こうした単語分散表現は他にも公開されています。\n",
    "「白ヤギコーポレーション」[^siroyagi] モデルは、やはり日本語ウィキペディアから学習されています。\n",
    "[^siroyagi]: <https://aial.shiroyagi.co.jp/2017/02/japanese-word2vec-model-builder/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "model_path = 'word2vec.gensim.model'\n",
    "model = Word2Vec.load(model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "name": "Chapter11_wordvectors.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
